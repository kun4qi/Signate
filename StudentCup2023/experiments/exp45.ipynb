{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcCertK8sk87","executionInfo":{"status":"ok","timestamp":1692411615774,"user_tz":-540,"elapsed":18151,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"284e6993-ee75-4714-b57e-8aa37cda3a4a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60y4waf9ss6H","executionInfo":{"status":"ok","timestamp":1692411627534,"user_tz":-540,"elapsed":6846,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"511475c6-994b-4663-9572-3038857fda8c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.11.3-py3-none-any.whl (225 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cmaes>=0.10.0 (from optuna)\n","  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.11.3 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"2uarR-RYsgEW","executionInfo":{"status":"ok","timestamp":1692413402342,"user_tz":-540,"elapsed":15503,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"outputs":[],"source":["# ===================================================================\n","#  Library\n","# ===================================================================\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import math\n","import time\n","\n","\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.metrics import mean_absolute_percentage_error\n","from tqdm.auto import tqdm\n","\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","import unicodedata\n","import lightgbm as lgb\n","\n","import optuna\n","import tensorflow as tf\n","from sklearn.metrics import mean_absolute_percentage_error\n","from tensorflow.keras.layers import Dense, PReLU\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qHC5RQzMsgEZ","executionInfo":{"status":"ok","timestamp":1692413402342,"user_tz":-540,"elapsed":16,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"outputs":[],"source":["# ===================================================================\n","#  CFG\n","# ===================================================================\n","class CFG:\n","    seed = 42\n","    n_trials = 3000\n","    num_pred = 13 #予測の数を指定、今回はexp38と39の2つ\n","    hidden_size = 16\n","    dropout = 0.2\n","    save_dir = '/content/drive/MyDrive/Colab Notebooks/signate2023/stacking/exp45/preds/'"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xAwmb2_IsgEa","executionInfo":{"status":"ok","timestamp":1692413402342,"user_tz":-540,"elapsed":15,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"outputs":[],"source":["# ===================================================================\n","#  Utils\n","# ===================================================================\n","def get_score(y_true, y_pred):\n","    \"\"\"get MAPE score\"\"\"\n","    score = mean_absolute_percentage_error(y_true, y_pred)\n","    return score * 100"]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/train.csv')"],"metadata":{"id":"PGfT8Rl7tO1F","executionInfo":{"status":"ok","timestamp":1692413402343,"user_tz":-540,"elapsed":16,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df_1 = pd.read_csv(CFG.save_dir+\"oof_df_exp014.csv\", names=['pred']).rename(columns={\"pred\":\"pred_1\"})\n","df_2 = pd.read_csv(CFG.save_dir+\"oof_df_exp015.csv\", names=['pred']).rename(columns={\"pred\":\"pred_2\"})\n","df_3 = pd.read_csv(CFG.save_dir+\"oof_df_exp016.csv\", names=['pred']).rename(columns={\"pred\":\"pred_3\"})\n","df_4 = pd.read_csv(CFG.save_dir+\"oof_df_exp017.csv\", names=['pred']).rename(columns={\"pred\":\"pred_4\"})\n","df_5 = pd.read_csv(CFG.save_dir+\"oof_df_exp018.csv\", names=['pred']).rename(columns={\"pred\":\"pred_5\"})\n","df_6 = pd.read_csv(CFG.save_dir+\"oof_df_exp019.csv\", names=['pred']).rename(columns={\"pred\":\"pred_6\"})\n","df_7 = pd.read_csv(CFG.save_dir+\"oof_df_exp020.csv\", names=['pred']).rename(columns={\"pred\":\"pred_7\"})\n","df_8 = pd.read_csv(CFG.save_dir+\"oof_df_exp021.csv\", names=['pred']).rename(columns={\"pred\":\"pred_8\"})\n","df_9 = pd.read_csv(CFG.save_dir+\"oof_df_exp022.csv\", names=['pred']).rename(columns={\"pred\":\"pred_9\"})\n","df_10 = pd.read_csv(CFG.save_dir+\"oof_df_exp023.csv\", names=['pred']).rename(columns={\"pred\":\"pred_10\"})\n","df_11 = pd.read_csv(CFG.save_dir+\"exp38_oof_pred.csv\").rename(columns={\"oof_pred\":\"pred_11\"})\n","df_12 = pd.read_csv(CFG.save_dir+\"exp39_oof_pred.csv\").rename(columns={\"oof_pred\":\"pred_12\"})\n","df_13 = pd.read_csv(CFG.save_dir+\"exp40_oof_pred.csv\").rename(columns={\"oof_pred\":\"pred_13\"})\n","\n","df = pd.concat([df_train['id'], df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10, df_11, df_12, df_13, df_train['price']], axis=1)\n","\n","\n","test_1 = pd.read_csv(CFG.save_dir+\"exp014.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_1\"})\n","test_2 = pd.read_csv(CFG.save_dir+\"exp015.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_2\"})\n","test_3 = pd.read_csv(CFG.save_dir+\"exp016.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_3\"})\n","test_4 = pd.read_csv(CFG.save_dir+\"exp017.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_4\"})\n","test_5 = pd.read_csv(CFG.save_dir+\"exp018.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_5\"})\n","test_6 = pd.read_csv(CFG.save_dir+\"exp019.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_6\"})\n","test_7 = pd.read_csv(CFG.save_dir+\"exp020.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_7\"})\n","test_8 = pd.read_csv(CFG.save_dir+\"exp021.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_8\"})\n","test_9 = pd.read_csv(CFG.save_dir+\"exp022.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_9\"})\n","test_10 = pd.read_csv(CFG.save_dir+\"exp023.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_10\"})\n","test_11 = pd.read_csv(CFG.save_dir+\"exp38.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_11\"})\n","test_12 = pd.read_csv(CFG.save_dir+\"exp39.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_12\"})\n","test_13 = pd.read_csv(CFG.save_dir+\"exp40.csv\", header=None).rename(columns={0:\"id\", 1:\"pred_13\"})\n","test = test_1.merge(test_2, on='id')\n","test = test.merge(test_3, on='id')\n","test = test.merge(test_4, on='id')\n","test = test.merge(test_5, on='id')\n","test = test.merge(test_6, on='id')\n","test = test.merge(test_7, on='id')\n","test = test.merge(test_8, on='id')\n","test = test.merge(test_9, on='id')\n","test = test.merge(test_10, on='id')\n","test = test.merge(test_11, on='id')\n","test = test.merge(test_12, on='id')\n","test = test.merge(test_13, on='id')"],"metadata":{"id":"jwehc82HkfWE","executionInfo":{"status":"ok","timestamp":1692413404051,"user_tz":-540,"elapsed":1724,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"FzUnDPQDnwH9","executionInfo":{"status":"ok","timestamp":1692413404053,"user_tz":-540,"elapsed":18,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"010fbd94-33b9-4e8a-c3be-0b9a9b007337"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id        pred_1        pred_2        pred_3        pred_4  \\\n","0          0   6881.892301   6517.414858   7476.567746   7052.610590   \n","1          1   3740.634027   3496.012582   3789.907986   3322.844722   \n","2          2   2954.247573   2735.110086   3288.647709   2893.840210   \n","3          3   8430.949224   8337.416095   9033.353098   8081.404050   \n","4          4   3972.418866   4254.790314   4089.549517   4272.046434   \n","...      ...           ...           ...           ...           ...   \n","27527  27527  12650.381284  13146.560575  12653.178198  11322.272339   \n","27528  27528   6494.944663   6633.645836   6184.736099   6171.310930   \n","27529  27529  12231.954239  15018.441231  14539.286659  14360.762819   \n","27530  27530   6832.933932   6911.537235   6877.397725   7139.135069   \n","27531  27531   9925.656545  10394.766809  11093.492499   9764.510313   \n","\n","             pred_5        pred_6        pred_7        pred_8        pred_9  \\\n","0       6809.002174   6465.089852   7714.185588   7010.855590   7184.306903   \n","1       3603.935425   3485.623398   3507.497452   3714.057283   3488.353022   \n","2       3253.350282   2885.690295   3202.103770   2799.365349   2989.931642   \n","3       8187.453186   8477.542430   8546.771462   8388.923127   8119.183310   \n","4       4446.949951   4022.828501   4374.413436   4369.679027   4150.709500   \n","...             ...           ...           ...           ...           ...   \n","27527  13596.740391  12324.404433  11482.192363  11724.735381  11434.271326   \n","27528   6500.089660   6209.227748   6202.691850   6608.664580   6505.449763   \n","27529  11463.997914  13025.753065  12083.865500  12834.191021  13653.370272   \n","27530   6847.030473   6937.347570   6261.849519   6822.260414   6649.630136   \n","27531   9884.158547  10122.238409   9578.433956  10051.294294   9915.128227   \n","\n","            pred_10     pred_11     pred_12     pred_13  price  \n","0       6364.997182   7118.9443   7627.1987   7084.0015  27587  \n","1       3750.770625   3660.8042   3526.6816   3732.6855   4724  \n","2       2920.912332   2883.7390   3149.7769   2995.7760  10931  \n","3       8413.930266   8650.6270   8943.9030   9243.1750  16553  \n","4       3941.880817   4031.1462   4406.5480   4107.9190   5158  \n","...             ...         ...         ...         ...    ...  \n","27527  13129.896185  12879.4610  13338.9980  12310.2180  32212  \n","27528   6262.582410   6693.9270   6920.0894   6770.7925   5400  \n","27529  11537.194512  14174.7040  15265.7090  14390.8955  22227  \n","27530   6443.098367   7086.4136   6367.2173   6483.3950   3054  \n","27531   9186.327488  10193.3470  10526.0670  10853.2540  20801  \n","\n","[27532 rows x 15 columns]"],"text/html":["\n","  <div id=\"df-713120a0-e8d9-4c79-b1b3-b9107ee74719\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pred_1</th>\n","      <th>pred_2</th>\n","      <th>pred_3</th>\n","      <th>pred_4</th>\n","      <th>pred_5</th>\n","      <th>pred_6</th>\n","      <th>pred_7</th>\n","      <th>pred_8</th>\n","      <th>pred_9</th>\n","      <th>pred_10</th>\n","      <th>pred_11</th>\n","      <th>pred_12</th>\n","      <th>pred_13</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>6881.892301</td>\n","      <td>6517.414858</td>\n","      <td>7476.567746</td>\n","      <td>7052.610590</td>\n","      <td>6809.002174</td>\n","      <td>6465.089852</td>\n","      <td>7714.185588</td>\n","      <td>7010.855590</td>\n","      <td>7184.306903</td>\n","      <td>6364.997182</td>\n","      <td>7118.9443</td>\n","      <td>7627.1987</td>\n","      <td>7084.0015</td>\n","      <td>27587</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3740.634027</td>\n","      <td>3496.012582</td>\n","      <td>3789.907986</td>\n","      <td>3322.844722</td>\n","      <td>3603.935425</td>\n","      <td>3485.623398</td>\n","      <td>3507.497452</td>\n","      <td>3714.057283</td>\n","      <td>3488.353022</td>\n","      <td>3750.770625</td>\n","      <td>3660.8042</td>\n","      <td>3526.6816</td>\n","      <td>3732.6855</td>\n","      <td>4724</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2954.247573</td>\n","      <td>2735.110086</td>\n","      <td>3288.647709</td>\n","      <td>2893.840210</td>\n","      <td>3253.350282</td>\n","      <td>2885.690295</td>\n","      <td>3202.103770</td>\n","      <td>2799.365349</td>\n","      <td>2989.931642</td>\n","      <td>2920.912332</td>\n","      <td>2883.7390</td>\n","      <td>3149.7769</td>\n","      <td>2995.7760</td>\n","      <td>10931</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>8430.949224</td>\n","      <td>8337.416095</td>\n","      <td>9033.353098</td>\n","      <td>8081.404050</td>\n","      <td>8187.453186</td>\n","      <td>8477.542430</td>\n","      <td>8546.771462</td>\n","      <td>8388.923127</td>\n","      <td>8119.183310</td>\n","      <td>8413.930266</td>\n","      <td>8650.6270</td>\n","      <td>8943.9030</td>\n","      <td>9243.1750</td>\n","      <td>16553</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>3972.418866</td>\n","      <td>4254.790314</td>\n","      <td>4089.549517</td>\n","      <td>4272.046434</td>\n","      <td>4446.949951</td>\n","      <td>4022.828501</td>\n","      <td>4374.413436</td>\n","      <td>4369.679027</td>\n","      <td>4150.709500</td>\n","      <td>3941.880817</td>\n","      <td>4031.1462</td>\n","      <td>4406.5480</td>\n","      <td>4107.9190</td>\n","      <td>5158</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27527</th>\n","      <td>27527</td>\n","      <td>12650.381284</td>\n","      <td>13146.560575</td>\n","      <td>12653.178198</td>\n","      <td>11322.272339</td>\n","      <td>13596.740391</td>\n","      <td>12324.404433</td>\n","      <td>11482.192363</td>\n","      <td>11724.735381</td>\n","      <td>11434.271326</td>\n","      <td>13129.896185</td>\n","      <td>12879.4610</td>\n","      <td>13338.9980</td>\n","      <td>12310.2180</td>\n","      <td>32212</td>\n","    </tr>\n","    <tr>\n","      <th>27528</th>\n","      <td>27528</td>\n","      <td>6494.944663</td>\n","      <td>6633.645836</td>\n","      <td>6184.736099</td>\n","      <td>6171.310930</td>\n","      <td>6500.089660</td>\n","      <td>6209.227748</td>\n","      <td>6202.691850</td>\n","      <td>6608.664580</td>\n","      <td>6505.449763</td>\n","      <td>6262.582410</td>\n","      <td>6693.9270</td>\n","      <td>6920.0894</td>\n","      <td>6770.7925</td>\n","      <td>5400</td>\n","    </tr>\n","    <tr>\n","      <th>27529</th>\n","      <td>27529</td>\n","      <td>12231.954239</td>\n","      <td>15018.441231</td>\n","      <td>14539.286659</td>\n","      <td>14360.762819</td>\n","      <td>11463.997914</td>\n","      <td>13025.753065</td>\n","      <td>12083.865500</td>\n","      <td>12834.191021</td>\n","      <td>13653.370272</td>\n","      <td>11537.194512</td>\n","      <td>14174.7040</td>\n","      <td>15265.7090</td>\n","      <td>14390.8955</td>\n","      <td>22227</td>\n","    </tr>\n","    <tr>\n","      <th>27530</th>\n","      <td>27530</td>\n","      <td>6832.933932</td>\n","      <td>6911.537235</td>\n","      <td>6877.397725</td>\n","      <td>7139.135069</td>\n","      <td>6847.030473</td>\n","      <td>6937.347570</td>\n","      <td>6261.849519</td>\n","      <td>6822.260414</td>\n","      <td>6649.630136</td>\n","      <td>6443.098367</td>\n","      <td>7086.4136</td>\n","      <td>6367.2173</td>\n","      <td>6483.3950</td>\n","      <td>3054</td>\n","    </tr>\n","    <tr>\n","      <th>27531</th>\n","      <td>27531</td>\n","      <td>9925.656545</td>\n","      <td>10394.766809</td>\n","      <td>11093.492499</td>\n","      <td>9764.510313</td>\n","      <td>9884.158547</td>\n","      <td>10122.238409</td>\n","      <td>9578.433956</td>\n","      <td>10051.294294</td>\n","      <td>9915.128227</td>\n","      <td>9186.327488</td>\n","      <td>10193.3470</td>\n","      <td>10526.0670</td>\n","      <td>10853.2540</td>\n","      <td>20801</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27532 rows × 15 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-713120a0-e8d9-4c79-b1b3-b9107ee74719')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-713120a0-e8d9-4c79-b1b3-b9107ee74719 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-713120a0-e8d9-4c79-b1b3-b9107ee74719');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9f6f37f5-756a-4d71-9993-892c2e64c142\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f6f37f5-756a-4d71-9993-892c2e64c142')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9f6f37f5-756a-4d71-9993-892c2e64c142 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"gw790T-roBrn","executionInfo":{"status":"ok","timestamp":1692413404053,"user_tz":-540,"elapsed":16,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"56c21c03-1c61-4427-df74-1193c592f95a"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          id        pred_1        pred_2        pred_3        pred_4  \\\n","0      27532   9665.240676   9060.741324   8931.822504   9993.239922   \n","1      27533   5140.878681   4974.611255   4485.057773   5533.795617   \n","2      27534   5628.236365   5804.522418   5796.571207   5726.217723   \n","3      27535  18624.817802  20021.162475  18835.327938  22007.952770   \n","4      27536   3625.637392   4375.456011   4220.231775   3687.370209   \n","...      ...           ...           ...           ...           ...   \n","27532  55064  14710.830942  11584.438744  11947.372568  13550.423259   \n","27533  55065   8852.779860   8068.844513   8619.407623   9115.885754   \n","27534  55066   6288.760858   6135.556787   6508.548628   6240.533655   \n","27535  55067   5168.341070   5594.025322   5106.247195   4975.679965   \n","27536  55068   5579.425944   5461.396498   5519.349375   5327.003678   \n","\n","             pred_5        pred_6        pred_7        pred_8        pred_9  \\\n","0       9387.607212   9908.462741  10128.928844   9738.111509  10579.697128   \n","1       5044.527731   4849.379307   5257.737182   5354.979862   5545.143501   \n","2       5822.816944   5759.308970   5798.455075   5419.099745   5595.549648   \n","3      18960.034958  19900.729462  19313.421537  18475.892150  19846.987451   \n","4       4082.474807   4105.429409   3789.946321   3915.428485   4189.230892   \n","...             ...           ...           ...           ...           ...   \n","27532  13646.679093  13303.559398  14155.207461  15621.013652  13879.446250   \n","27533   8196.746981   7947.659290   8410.227937   8646.502454   8689.880353   \n","27534   5993.522277   5874.218495   6160.884478   6478.396730   6060.177626   \n","27535   5220.941190   5072.216882   4967.672649   5048.859101   5397.634268   \n","27536   5459.886713   5507.400734   5250.434000   5710.001197   5305.866783   \n","\n","            pred_10       pred_11       pred_12       pred_13  \n","0      10122.133738   9462.117521   9616.369529   9455.621674  \n","1       5494.171219   5431.933504   5579.297671   5502.604659  \n","2       5898.592901   5563.460291   5543.298528   5644.606929  \n","3      20655.747438  19615.535011  19333.748566  19484.368965  \n","4       3982.415899   4165.521012   4132.487296   4262.280629  \n","...             ...           ...           ...           ...  \n","27532  13562.673696  13342.552114  13667.855920  13413.909141  \n","27533   8737.035801   8482.824014   8544.580408   8316.495493  \n","27534   5956.305561   6235.427898   6279.775623   6330.773011  \n","27535   5314.368811   5198.181210   5218.070387   5204.748284  \n","27536   5146.788648   5747.142214   5739.231787   5807.363484  \n","\n","[27537 rows x 14 columns]"],"text/html":["\n","  <div id=\"df-a4f099bc-66e9-42b4-bc52-6c2c68545525\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>pred_1</th>\n","      <th>pred_2</th>\n","      <th>pred_3</th>\n","      <th>pred_4</th>\n","      <th>pred_5</th>\n","      <th>pred_6</th>\n","      <th>pred_7</th>\n","      <th>pred_8</th>\n","      <th>pred_9</th>\n","      <th>pred_10</th>\n","      <th>pred_11</th>\n","      <th>pred_12</th>\n","      <th>pred_13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>27532</td>\n","      <td>9665.240676</td>\n","      <td>9060.741324</td>\n","      <td>8931.822504</td>\n","      <td>9993.239922</td>\n","      <td>9387.607212</td>\n","      <td>9908.462741</td>\n","      <td>10128.928844</td>\n","      <td>9738.111509</td>\n","      <td>10579.697128</td>\n","      <td>10122.133738</td>\n","      <td>9462.117521</td>\n","      <td>9616.369529</td>\n","      <td>9455.621674</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27533</td>\n","      <td>5140.878681</td>\n","      <td>4974.611255</td>\n","      <td>4485.057773</td>\n","      <td>5533.795617</td>\n","      <td>5044.527731</td>\n","      <td>4849.379307</td>\n","      <td>5257.737182</td>\n","      <td>5354.979862</td>\n","      <td>5545.143501</td>\n","      <td>5494.171219</td>\n","      <td>5431.933504</td>\n","      <td>5579.297671</td>\n","      <td>5502.604659</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>27534</td>\n","      <td>5628.236365</td>\n","      <td>5804.522418</td>\n","      <td>5796.571207</td>\n","      <td>5726.217723</td>\n","      <td>5822.816944</td>\n","      <td>5759.308970</td>\n","      <td>5798.455075</td>\n","      <td>5419.099745</td>\n","      <td>5595.549648</td>\n","      <td>5898.592901</td>\n","      <td>5563.460291</td>\n","      <td>5543.298528</td>\n","      <td>5644.606929</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>27535</td>\n","      <td>18624.817802</td>\n","      <td>20021.162475</td>\n","      <td>18835.327938</td>\n","      <td>22007.952770</td>\n","      <td>18960.034958</td>\n","      <td>19900.729462</td>\n","      <td>19313.421537</td>\n","      <td>18475.892150</td>\n","      <td>19846.987451</td>\n","      <td>20655.747438</td>\n","      <td>19615.535011</td>\n","      <td>19333.748566</td>\n","      <td>19484.368965</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>27536</td>\n","      <td>3625.637392</td>\n","      <td>4375.456011</td>\n","      <td>4220.231775</td>\n","      <td>3687.370209</td>\n","      <td>4082.474807</td>\n","      <td>4105.429409</td>\n","      <td>3789.946321</td>\n","      <td>3915.428485</td>\n","      <td>4189.230892</td>\n","      <td>3982.415899</td>\n","      <td>4165.521012</td>\n","      <td>4132.487296</td>\n","      <td>4262.280629</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27532</th>\n","      <td>55064</td>\n","      <td>14710.830942</td>\n","      <td>11584.438744</td>\n","      <td>11947.372568</td>\n","      <td>13550.423259</td>\n","      <td>13646.679093</td>\n","      <td>13303.559398</td>\n","      <td>14155.207461</td>\n","      <td>15621.013652</td>\n","      <td>13879.446250</td>\n","      <td>13562.673696</td>\n","      <td>13342.552114</td>\n","      <td>13667.855920</td>\n","      <td>13413.909141</td>\n","    </tr>\n","    <tr>\n","      <th>27533</th>\n","      <td>55065</td>\n","      <td>8852.779860</td>\n","      <td>8068.844513</td>\n","      <td>8619.407623</td>\n","      <td>9115.885754</td>\n","      <td>8196.746981</td>\n","      <td>7947.659290</td>\n","      <td>8410.227937</td>\n","      <td>8646.502454</td>\n","      <td>8689.880353</td>\n","      <td>8737.035801</td>\n","      <td>8482.824014</td>\n","      <td>8544.580408</td>\n","      <td>8316.495493</td>\n","    </tr>\n","    <tr>\n","      <th>27534</th>\n","      <td>55066</td>\n","      <td>6288.760858</td>\n","      <td>6135.556787</td>\n","      <td>6508.548628</td>\n","      <td>6240.533655</td>\n","      <td>5993.522277</td>\n","      <td>5874.218495</td>\n","      <td>6160.884478</td>\n","      <td>6478.396730</td>\n","      <td>6060.177626</td>\n","      <td>5956.305561</td>\n","      <td>6235.427898</td>\n","      <td>6279.775623</td>\n","      <td>6330.773011</td>\n","    </tr>\n","    <tr>\n","      <th>27535</th>\n","      <td>55067</td>\n","      <td>5168.341070</td>\n","      <td>5594.025322</td>\n","      <td>5106.247195</td>\n","      <td>4975.679965</td>\n","      <td>5220.941190</td>\n","      <td>5072.216882</td>\n","      <td>4967.672649</td>\n","      <td>5048.859101</td>\n","      <td>5397.634268</td>\n","      <td>5314.368811</td>\n","      <td>5198.181210</td>\n","      <td>5218.070387</td>\n","      <td>5204.748284</td>\n","    </tr>\n","    <tr>\n","      <th>27536</th>\n","      <td>55068</td>\n","      <td>5579.425944</td>\n","      <td>5461.396498</td>\n","      <td>5519.349375</td>\n","      <td>5327.003678</td>\n","      <td>5459.886713</td>\n","      <td>5507.400734</td>\n","      <td>5250.434000</td>\n","      <td>5710.001197</td>\n","      <td>5305.866783</td>\n","      <td>5146.788648</td>\n","      <td>5747.142214</td>\n","      <td>5739.231787</td>\n","      <td>5807.363484</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27537 rows × 14 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4f099bc-66e9-42b4-bc52-6c2c68545525')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a4f099bc-66e9-42b4-bc52-6c2c68545525 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a4f099bc-66e9-42b4-bc52-6c2c68545525');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cf4133cd-0cbc-4b97-98a5-5e90c9d4f37a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf4133cd-0cbc-4b97-98a5-5e90c9d4f37a')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cf4133cd-0cbc-4b97-98a5-5e90c9d4f37a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def mape_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    diff = tf.abs((y_true - y_pred) / tf.clip_by_value(tf.abs(y_true), 1e-9, float(\"inf\")))\n","    return 100. * tf.reduce_mean(diff)"],"metadata":{"id":"XXhR478jAUo8","executionInfo":{"status":"ok","timestamp":1692413404053,"user_tz":-540,"elapsed":15,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","set_seed(42)  # ここでシード値を設定"],"metadata":{"id":"VIS0sOQq-KVC","executionInfo":{"status":"ok","timestamp":1692413404054,"user_tz":-540,"elapsed":15,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 交差検証関数の定義\n","def get_custom_cv(df, n_splits):\n","    df = df.sort_values(by=\"price\", ignore_index=True)\n","    df[\"fold\"] = [i for i in range(n_splits)] * (df.shape[0] // n_splits) \\\n","                + [i for i in range(df.shape[0] % n_splits)]\n","    df = df.sort_values(by=\"id\", ignore_index=True)\n","\n","    for fold in range(n_splits):\n","        train_idx = df[df[\"fold\"] != fold].index\n","        valid_idx = df[df[\"fold\"] == fold].index\n","        yield train_idx, valid_idx\n","\n","# CVの設定\n","n_splits = 8\n","cv = list(get_custom_cv(df, n_splits))"],"metadata":{"id":"iiQWoIsi-oxU","executionInfo":{"status":"ok","timestamp":1692413404054,"user_tz":-540,"elapsed":15,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yD0BLcMrKqAB","executionInfo":{"status":"ok","timestamp":1692413404054,"user_tz":-540,"elapsed":15,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 1. データセットの作成\n","X = df[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7', 'pred_8', 'pred_9', 'pred_10', 'pred_11', 'pred_12', 'pred_13']].values\n","y = df['price'].values"],"metadata":{"id":"Yd-CiZAMAV2Y","executionInfo":{"status":"ok","timestamp":1692413404492,"user_tz":-540,"elapsed":453,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#一つ目のモデル"],"metadata":{"id":"IDmpPWq1R5Ha","executionInfo":{"status":"ok","timestamp":1692413404492,"user_tz":-540,"elapsed":9,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# テストデータの特徴量の取得\n","test_features = test[['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7', 'pred_8', 'pred_9', 'pred_10', 'pred_11', 'pred_12', 'pred_13']].values\n","\n","# 各フォールドでのテストデータの予測を格納するリスト\n","test_preds = []\n","\n","# OOF (Out Of Fold) predictions\n","oof_preds = np.zeros_like(y)\n","\n","for fold, (train_idx, valid_idx) in enumerate(cv):\n","    print(f\"Fold {fold + 1}\")\n","\n","    # データの取得\n","    X_train, y_train = X[train_idx], y[train_idx]\n","    X_valid, y_valid = X[valid_idx], y[valid_idx]\n","\n","    # モデルの作成と学習\n","    model = Sequential([\n","        Dense(CFG.hidden_size*3, input_dim=CFG.num_pred),\n","        PReLU(),\n","        Dense(CFG.hidden_size*2),\n","        PReLU(),\n","        Dense(CFG.hidden_size),\n","        PReLU(),\n","        Dense(1)\n","    ])\n","\n","    model.compile(optimizer=Adam(), loss=mape_loss)\n","\n","    # EarlyStoppingコールバックの定義\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n","\n","    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=32, verbose=1, callbacks=[early_stopping])\n","\n","    # OOF predictions\n","    oof_preds[valid_idx] = model.predict(X_valid).reshape(-1)\n","\n","    print(f\"FINISHI: fold{fold} Score: {mean_absolute_percentage_error(y_valid, oof_preds[valid_idx]):.4f}\")\n","\n","    # テストデータの予測\n","    test_pred = model.predict(test_features).reshape(-1)\n","    test_preds.append(test_pred)\n","\n","# Calculate overall OOF score\n","oof_score = mean_absolute_percentage_error(y, oof_preds)\n","print(\"=\" * 50)\n","print(f\"FINISHI: Whole OOF Score: {oof_score:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8EjG5jb7hul","executionInfo":{"status":"ok","timestamp":1692414481782,"user_tz":-540,"elapsed":1077298,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"e6d49cf9-8aad-498e-8428-0ba1cc6eba9f"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n","Epoch 1/50\n","753/753 [==============================] - 9s 4ms/step - loss: 44.8640 - val_loss: 43.3984\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1460 - val_loss: 43.3883\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1449 - val_loss: 43.3960\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1032 - val_loss: 43.6948\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1432 - val_loss: 43.4734\n","Epoch 6/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0861 - val_loss: 43.6089\n","Epoch 7/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1036 - val_loss: 43.3782\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1068 - val_loss: 43.3800\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0881 - val_loss: 43.3887\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0814 - val_loss: 43.3986\n","Epoch 11/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1055 - val_loss: 43.4139\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0577 - val_loss: 43.3758\n","Epoch 13/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1048 - val_loss: 43.3801\n","Epoch 14/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0582 - val_loss: 43.4035\n","Epoch 15/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0690 - val_loss: 43.3872\n","Epoch 16/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0755 - val_loss: 43.3840\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0343 - val_loss: 43.3967\n","Epoch 18/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0201 - val_loss: 43.3957\n","Epoch 19/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0494 - val_loss: 43.3977\n","Epoch 20/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0494 - val_loss: 43.4074\n","Epoch 21/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0398 - val_loss: 43.6763\n","Epoch 22/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0469 - val_loss: 43.3984\n","Epoch 23/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0243 - val_loss: 43.3948\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0657 - val_loss: 43.6399\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0276 - val_loss: 43.7050\n","Epoch 26/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0265 - val_loss: 43.3879\n","Epoch 27/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0251 - val_loss: 43.4308\n","Epoch 28/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0095 - val_loss: 43.5955\n","Epoch 29/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0195 - val_loss: 43.6064\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0069 - val_loss: 43.4591\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0298 - val_loss: 43.3850\n","Epoch 32/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0325 - val_loss: 43.5409\n","Epoch 33/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0169 - val_loss: 43.5080\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0367 - val_loss: 43.5138\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0417 - val_loss: 44.0764\n","Epoch 36/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0238 - val_loss: 43.4261\n","Epoch 37/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9889 - val_loss: 43.5962\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0384 - val_loss: 43.7903\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0276 - val_loss: 43.4179\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0173 - val_loss: 43.4017\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0244 - val_loss: 43.4354\n","Epoch 42/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0477 - val_loss: 43.4060\n","Epoch 43/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0089 - val_loss: 43.4539\n","Epoch 44/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0265 - val_loss: 43.3970\n","Epoch 45/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0667 - val_loss: 43.4564\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9984 - val_loss: 43.3855\n","Epoch 47/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0172 - val_loss: 43.3891\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0419 - val_loss: 43.4196\n","Epoch 49/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9910 - val_loss: 43.3854\n","Epoch 50/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9972 - val_loss: 43.5372\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold0 Score: 0.4354\n","861/861 [==============================] - 2s 2ms/step\n","Fold 2\n","Epoch 1/50\n","753/753 [==============================] - 4s 3ms/step - loss: 44.2294 - val_loss: 44.5531\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9474 - val_loss: 44.7109\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0249 - val_loss: 44.4870\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9814 - val_loss: 44.4903\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9311 - val_loss: 44.5485\n","Epoch 6/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9338 - val_loss: 44.4785\n","Epoch 7/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8946 - val_loss: 44.4900\n","Epoch 8/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8971 - val_loss: 44.5474\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9713 - val_loss: 44.8943\n","Epoch 10/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9700 - val_loss: 44.4658\n","Epoch 11/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8803 - val_loss: 44.7018\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9077 - val_loss: 44.4621\n","Epoch 13/50\n","753/753 [==============================] - 4s 5ms/step - loss: 43.9409 - val_loss: 45.1565\n","Epoch 14/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8904 - val_loss: 44.4852\n","Epoch 15/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8770 - val_loss: 44.4683\n","Epoch 16/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9033 - val_loss: 44.8120\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8827 - val_loss: 44.5538\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8940 - val_loss: 44.7662\n","Epoch 19/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9137 - val_loss: 44.4627\n","Epoch 20/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8810 - val_loss: 44.5136\n","Epoch 21/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8651 - val_loss: 44.7393\n","Epoch 22/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8933 - val_loss: 44.4902\n","Epoch 23/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8760 - val_loss: 45.1244\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8874 - val_loss: 44.5350\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9492 - val_loss: 44.4810\n","Epoch 26/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8580 - val_loss: 44.4816\n","Epoch 27/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8567 - val_loss: 44.4606\n","Epoch 28/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8778 - val_loss: 44.5039\n","Epoch 29/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8846 - val_loss: 44.4710\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8921 - val_loss: 44.5200\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8992 - val_loss: 45.0549\n","Epoch 32/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8842 - val_loss: 44.7899\n","Epoch 33/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8832 - val_loss: 44.4585\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8286 - val_loss: 44.5451\n","Epoch 35/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8598 - val_loss: 44.8345\n","Epoch 36/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9187 - val_loss: 44.4592\n","Epoch 37/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8428 - val_loss: 44.5818\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8604 - val_loss: 44.4970\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8368 - val_loss: 44.5817\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8356 - val_loss: 44.4639\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9010 - val_loss: 44.4898\n","Epoch 42/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8424 - val_loss: 44.5508\n","Epoch 43/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8820 - val_loss: 44.5894\n","Epoch 44/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8621 - val_loss: 44.8815\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8418 - val_loss: 44.5697\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8315 - val_loss: 44.4801\n","Epoch 47/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8294 - val_loss: 44.9437\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8639 - val_loss: 44.5078\n","Epoch 49/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8791 - val_loss: 44.5413\n","Epoch 50/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8467 - val_loss: 44.6769\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold1 Score: 0.4468\n","861/861 [==============================] - 2s 2ms/step\n","Fold 3\n","Epoch 1/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.8223 - val_loss: 44.3083\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1646 - val_loss: 43.5516\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0919 - val_loss: 43.6809\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0822 - val_loss: 43.5857\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0648 - val_loss: 43.7708\n","Epoch 6/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1229 - val_loss: 43.5376\n","Epoch 7/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0856 - val_loss: 43.5526\n","Epoch 8/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0930 - val_loss: 43.5126\n","Epoch 9/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0311 - val_loss: 43.8854\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0137 - val_loss: 43.7621\n","Epoch 11/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0177 - val_loss: 43.6807\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0617 - val_loss: 43.5097\n","Epoch 13/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0381 - val_loss: 43.6692\n","Epoch 14/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0933 - val_loss: 44.0829\n","Epoch 15/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9790 - val_loss: 43.5697\n","Epoch 16/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0161 - val_loss: 43.6513\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0440 - val_loss: 43.5456\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0262 - val_loss: 43.5207\n","Epoch 19/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0191 - val_loss: 43.5412\n","Epoch 20/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9983 - val_loss: 43.5709\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9898 - val_loss: 43.9616\n","Epoch 22/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9900 - val_loss: 43.5253\n","Epoch 23/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0158 - val_loss: 43.5320\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9766 - val_loss: 43.5074\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0477 - val_loss: 43.5897\n","Epoch 26/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9648 - val_loss: 43.7165\n","Epoch 27/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0089 - val_loss: 43.5159\n","Epoch 28/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0209 - val_loss: 43.8673\n","Epoch 29/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0136 - val_loss: 43.6535\n","Epoch 30/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9967 - val_loss: 43.6856\n","Epoch 31/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9931 - val_loss: 43.5084\n","Epoch 32/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9972 - val_loss: 43.7138\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9822 - val_loss: 43.7625\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0216 - val_loss: 43.6036\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9961 - val_loss: 43.6585\n","Epoch 36/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0127 - val_loss: 43.6031\n","Epoch 37/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0300 - val_loss: 43.6886\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0124 - val_loss: 43.5192\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9760 - val_loss: 43.5091\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0159 - val_loss: 43.5243\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9903 - val_loss: 43.5109\n","Epoch 42/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9910 - val_loss: 43.5192\n","Epoch 43/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9759 - val_loss: 43.5625\n","Epoch 44/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0070 - val_loss: 43.5546\n","Epoch 45/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9926 - val_loss: 43.8937\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0045 - val_loss: 43.5356\n","Epoch 47/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9942 - val_loss: 43.5098\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9832 - val_loss: 43.5346\n","Epoch 49/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9992 - val_loss: 43.5713\n","Epoch 50/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9852 - val_loss: 43.5365\n","108/108 [==============================] - 0s 1ms/step\n","FINISHI: fold2 Score: 0.4354\n","861/861 [==============================] - 2s 2ms/step\n","Fold 4\n","Epoch 1/50\n","753/753 [==============================] - 4s 3ms/step - loss: 45.3291 - val_loss: 44.8813\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8868 - val_loss: 44.8290\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8512 - val_loss: 44.8319\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9041 - val_loss: 44.9442\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8789 - val_loss: 45.2385\n","Epoch 6/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9019 - val_loss: 44.8910\n","Epoch 7/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8525 - val_loss: 44.8584\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8478 - val_loss: 44.8530\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8683 - val_loss: 44.8287\n","Epoch 10/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8294 - val_loss: 45.6115\n","Epoch 11/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8628 - val_loss: 45.0305\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8772 - val_loss: 45.1005\n","Epoch 13/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8136 - val_loss: 44.8585\n","Epoch 14/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8657 - val_loss: 45.1029\n","Epoch 15/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8628 - val_loss: 44.8209\n","Epoch 16/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8572 - val_loss: 44.8467\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.7954 - val_loss: 44.9434\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8346 - val_loss: 44.9573\n","Epoch 19/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8729 - val_loss: 44.8457\n","Epoch 20/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.7975 - val_loss: 44.8206\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8210 - val_loss: 44.8560\n","Epoch 22/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8283 - val_loss: 44.8727\n","Epoch 23/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8182 - val_loss: 44.8181\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8680 - val_loss: 44.8461\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8170 - val_loss: 44.9925\n","Epoch 26/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.7896 - val_loss: 44.9450\n","Epoch 27/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8160 - val_loss: 44.8656\n","Epoch 28/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8174 - val_loss: 44.8370\n","Epoch 29/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8276 - val_loss: 44.8290\n","Epoch 30/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8180 - val_loss: 44.8408\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8035 - val_loss: 44.8835\n","Epoch 32/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.7703 - val_loss: 44.8282\n","Epoch 33/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8407 - val_loss: 44.9403\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.7895 - val_loss: 44.9185\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8038 - val_loss: 44.8680\n","Epoch 36/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8192 - val_loss: 44.8459\n","Epoch 37/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8037 - val_loss: 44.8577\n","Epoch 38/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8336 - val_loss: 44.8578\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8266 - val_loss: 44.8182\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8245 - val_loss: 44.8214\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8354 - val_loss: 44.8782\n","Epoch 42/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8139 - val_loss: 45.0062\n","Epoch 43/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.7737 - val_loss: 44.8771\n","Epoch 44/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8033 - val_loss: 44.8220\n","Epoch 45/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.7838 - val_loss: 44.8828\n","Epoch 46/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.7931 - val_loss: 45.1208\n","Epoch 47/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.7938 - val_loss: 44.8907\n","Epoch 48/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8328 - val_loss: 44.8671\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8092 - val_loss: 44.9631\n","Epoch 50/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.7873 - val_loss: 45.0302\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold3 Score: 0.4503\n","861/861 [==============================] - 2s 2ms/step\n","Fold 5\n","Epoch 1/50\n","753/753 [==============================] - 4s 3ms/step - loss: 45.4407 - val_loss: 43.6827\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0927 - val_loss: 43.2830\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1062 - val_loss: 43.6496\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1674 - val_loss: 43.1502\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0768 - val_loss: 43.4109\n","Epoch 6/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1399 - val_loss: 43.2771\n","Epoch 7/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0647 - val_loss: 43.2123\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1140 - val_loss: 43.6316\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0915 - val_loss: 43.6692\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0905 - val_loss: 43.1497\n","Epoch 11/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1616 - val_loss: 43.3186\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1544 - val_loss: 43.1933\n","Epoch 13/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0933 - val_loss: 43.9213\n","Epoch 14/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0794 - val_loss: 43.3055\n","Epoch 15/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0784 - val_loss: 43.4848\n","Epoch 16/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0974 - val_loss: 43.1512\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1124 - val_loss: 43.1745\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0754 - val_loss: 43.1738\n","Epoch 19/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0841 - val_loss: 43.3215\n","Epoch 20/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0661 - val_loss: 43.1626\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0576 - val_loss: 43.1596\n","Epoch 22/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0709 - val_loss: 43.2232\n","Epoch 23/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0641 - val_loss: 43.2980\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0740 - val_loss: 43.1820\n","Epoch 25/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0549 - val_loss: 43.4395\n","Epoch 26/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0552 - val_loss: 43.1456\n","Epoch 27/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0513 - val_loss: 43.1641\n","Epoch 28/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0321 - val_loss: 43.1994\n","Epoch 29/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0577 - val_loss: 43.1698\n","Epoch 30/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0409 - val_loss: 43.1462\n","Epoch 31/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0666 - val_loss: 43.2490\n","Epoch 32/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0930 - val_loss: 43.3894\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0573 - val_loss: 43.1512\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0311 - val_loss: 43.1605\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0313 - val_loss: 43.3919\n","Epoch 36/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0546 - val_loss: 43.1611\n","Epoch 37/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0546 - val_loss: 43.5078\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0357 - val_loss: 43.1663\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0317 - val_loss: 43.1603\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0429 - val_loss: 43.4738\n","Epoch 41/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0264 - val_loss: 43.1609\n","Epoch 42/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0392 - val_loss: 43.4492\n","Epoch 43/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0402 - val_loss: 43.1615\n","Epoch 44/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0461 - val_loss: 43.1802\n","Epoch 45/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0593 - val_loss: 43.1680\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0279 - val_loss: 43.1462\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0419 - val_loss: 43.3914\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0600 - val_loss: 43.1837\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0152 - val_loss: 43.2507\n","Epoch 50/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0192 - val_loss: 43.1644\n","108/108 [==============================] - 0s 1ms/step\n","FINISHI: fold4 Score: 0.4316\n","861/861 [==============================] - 2s 2ms/step\n","Fold 6\n","Epoch 1/50\n","753/753 [==============================] - 4s 3ms/step - loss: 45.8271 - val_loss: 43.2063\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1902 - val_loss: 43.7116\n","Epoch 3/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1354 - val_loss: 43.1187\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1465 - val_loss: 43.2366\n","Epoch 5/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1236 - val_loss: 43.3586\n","Epoch 6/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1292 - val_loss: 43.1415\n","Epoch 7/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1356 - val_loss: 43.0983\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1045 - val_loss: 43.5809\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1364 - val_loss: 43.1577\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1222 - val_loss: 43.1850\n","Epoch 11/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0902 - val_loss: 43.0971\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1216 - val_loss: 44.0071\n","Epoch 13/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1238 - val_loss: 43.2917\n","Epoch 14/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1366 - val_loss: 43.7453\n","Epoch 15/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1136 - val_loss: 43.7800\n","Epoch 16/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1488 - val_loss: 43.2599\n","Epoch 17/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0808 - val_loss: 43.4051\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0962 - val_loss: 43.0991\n","Epoch 19/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0873 - val_loss: 43.9959\n","Epoch 20/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0441 - val_loss: 43.1313\n","Epoch 21/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1137 - val_loss: 44.1514\n","Epoch 22/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0590 - val_loss: 43.1192\n","Epoch 23/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1104 - val_loss: 43.0996\n","Epoch 24/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0658 - val_loss: 43.1005\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1612 - val_loss: 43.0978\n","Epoch 26/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1221 - val_loss: 43.1144\n","Epoch 27/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0811 - val_loss: 43.3988\n","Epoch 28/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0793 - val_loss: 43.5421\n","Epoch 29/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0832 - val_loss: 43.1341\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0569 - val_loss: 43.2266\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0755 - val_loss: 43.2028\n","Epoch 32/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0639 - val_loss: 43.1015\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0557 - val_loss: 43.8280\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0470 - val_loss: 43.3291\n","Epoch 35/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0543 - val_loss: 43.3366\n","Epoch 36/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0799 - val_loss: 43.4105\n","Epoch 37/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0542 - val_loss: 43.1070\n","Epoch 38/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0855 - val_loss: 43.1689\n","Epoch 39/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0891 - val_loss: 43.1292\n","Epoch 40/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0702 - val_loss: 43.2920\n","Epoch 41/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0438 - val_loss: 43.1481\n","Epoch 42/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1040 - val_loss: 43.1272\n","Epoch 43/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0512 - val_loss: 43.2155\n","Epoch 44/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0454 - val_loss: 43.1118\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0354 - val_loss: 43.1349\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0625 - val_loss: 43.1461\n","Epoch 47/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0530 - val_loss: 43.2125\n","Epoch 48/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1268 - val_loss: 43.1255\n","Epoch 49/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0657 - val_loss: 43.3413\n","Epoch 50/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0812 - val_loss: 43.4008\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold5 Score: 0.4340\n","861/861 [==============================] - 1s 1ms/step\n","Fold 7\n","Epoch 1/50\n","753/753 [==============================] - 5s 4ms/step - loss: 44.0496 - val_loss: 44.6220\n","Epoch 2/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9681 - val_loss: 44.6920\n","Epoch 3/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0261 - val_loss: 44.8938\n","Epoch 4/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8961 - val_loss: 46.2257\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8972 - val_loss: 44.8077\n","Epoch 6/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9506 - val_loss: 45.2661\n","Epoch 7/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9028 - val_loss: 45.1293\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8800 - val_loss: 45.4756\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8938 - val_loss: 44.7698\n","Epoch 10/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8667 - val_loss: 44.7210\n","Epoch 11/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8707 - val_loss: 44.6579\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8872 - val_loss: 45.0622\n","Epoch 13/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9338 - val_loss: 45.0447\n","Epoch 14/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9015 - val_loss: 44.7801\n","Epoch 15/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8666 - val_loss: 44.8367\n","Epoch 16/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8752 - val_loss: 44.6000\n","Epoch 17/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8550 - val_loss: 44.6409\n","Epoch 18/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8638 - val_loss: 44.6681\n","Epoch 19/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8866 - val_loss: 45.5838\n","Epoch 20/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8658 - val_loss: 44.6257\n","Epoch 21/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8338 - val_loss: 44.9819\n","Epoch 22/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8724 - val_loss: 45.1691\n","Epoch 23/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8329 - val_loss: 44.6013\n","Epoch 24/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8726 - val_loss: 44.8371\n","Epoch 25/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8422 - val_loss: 44.6755\n","Epoch 26/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8712 - val_loss: 44.6766\n","Epoch 27/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8252 - val_loss: 44.6875\n","Epoch 28/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8477 - val_loss: 44.7841\n","Epoch 29/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8746 - val_loss: 44.6279\n","Epoch 30/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8286 - val_loss: 45.0429\n","Epoch 31/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8263 - val_loss: 44.7094\n","Epoch 32/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8879 - val_loss: 44.7256\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8450 - val_loss: 44.7350\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8355 - val_loss: 44.6269\n","Epoch 35/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8578 - val_loss: 44.6043\n","Epoch 36/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8879 - val_loss: 44.6629\n","Epoch 37/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8631 - val_loss: 44.6105\n","Epoch 38/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8778 - val_loss: 45.0203\n","Epoch 39/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8157 - val_loss: 45.3511\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8484 - val_loss: 44.7734\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8507 - val_loss: 44.6461\n","Epoch 42/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8532 - val_loss: 44.7933\n","Epoch 43/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8239 - val_loss: 44.6912\n","Epoch 44/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.8511 - val_loss: 44.6614\n","Epoch 45/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.8622 - val_loss: 44.6867\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8435 - val_loss: 44.7164\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8258 - val_loss: 44.9669\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8568 - val_loss: 44.7490\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.8578 - val_loss: 45.4429\n","Epoch 50/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.8360 - val_loss: 44.6092\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold6 Score: 0.4461\n","861/861 [==============================] - 2s 2ms/step\n","Fold 8\n","Epoch 1/50\n","753/753 [==============================] - 4s 3ms/step - loss: 44.6211 - val_loss: 44.2586\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1404 - val_loss: 43.7988\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1045 - val_loss: 43.9337\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0985 - val_loss: 43.8508\n","Epoch 5/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0765 - val_loss: 43.9592\n","Epoch 6/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0340 - val_loss: 43.8499\n","Epoch 7/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0672 - val_loss: 43.7977\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0489 - val_loss: 44.0090\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0591 - val_loss: 43.7994\n","Epoch 10/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9969 - val_loss: 43.8670\n","Epoch 11/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0489 - val_loss: 43.8338\n","Epoch 12/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0144 - val_loss: 45.1309\n","Epoch 13/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0414 - val_loss: 43.8820\n","Epoch 14/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0231 - val_loss: 45.1325\n","Epoch 15/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9983 - val_loss: 44.2354\n","Epoch 16/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9986 - val_loss: 43.8218\n","Epoch 17/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9947 - val_loss: 43.8144\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0073 - val_loss: 43.8107\n","Epoch 19/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0428 - val_loss: 43.8264\n","Epoch 20/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0117 - val_loss: 43.8884\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0025 - val_loss: 43.8611\n","Epoch 22/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9721 - val_loss: 44.2691\n","Epoch 23/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0174 - val_loss: 43.9021\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9862 - val_loss: 44.0061\n","Epoch 25/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9657 - val_loss: 43.8365\n","Epoch 26/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9731 - val_loss: 43.8556\n","Epoch 27/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9999 - val_loss: 44.2132\n","Epoch 28/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0084 - val_loss: 43.8248\n","Epoch 29/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0091 - val_loss: 43.8358\n","Epoch 30/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0246 - val_loss: 43.8298\n","Epoch 31/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9328 - val_loss: 44.9021\n","Epoch 32/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9823 - val_loss: 43.8155\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9509 - val_loss: 44.0047\n","Epoch 34/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9520 - val_loss: 44.0756\n","Epoch 35/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9571 - val_loss: 43.9799\n","Epoch 36/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9564 - val_loss: 43.8724\n","Epoch 37/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9702 - val_loss: 43.8461\n","Epoch 38/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9821 - val_loss: 43.8565\n","Epoch 39/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9678 - val_loss: 43.8579\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9840 - val_loss: 43.8247\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9315 - val_loss: 43.9632\n","Epoch 42/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9684 - val_loss: 44.1310\n","Epoch 43/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9502 - val_loss: 44.2208\n","Epoch 44/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9847 - val_loss: 44.0412\n","Epoch 45/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9619 - val_loss: 43.8196\n","Epoch 46/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9501 - val_loss: 43.8451\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9504 - val_loss: 43.8289\n","Epoch 48/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9838 - val_loss: 43.9928\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9680 - val_loss: 44.3730\n","Epoch 50/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9422 - val_loss: 43.9988\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold7 Score: 0.4400\n","861/861 [==============================] - 2s 2ms/step\n","==================================================\n","FINISHI: Whole OOF Score: 0.4399\n"]}]},{"cell_type":"code","source":["hidden_size = 8\n","FINISHI: Whole OOF Score: 0.4395\n","\n","hidden_size = 16\n","FINISHI: Whole OOF Score: 0.4399"],"metadata":{"id":"hzrsnzBdIwe3","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"error","timestamp":1692414481783,"user_tz":-540,"elapsed":19,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"e9a790f7-6491-4308-dd55-b98c2097ca0f"},"execution_count":14,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mast_parse\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mArguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         and are passed to the built-in compile function.\"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_compiler_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSyntaxError\u001b[0m: invalid syntax (<ipython-input-14-111e2342233c>, line 2)"]}]},{"cell_type":"code","source":["#二つ目のモデル、こっちはあんまり期待できなさそうかも？"],"metadata":{"id":"fHGMPXqWSlBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","from keras.models import Sequential\n","from keras.layers import Dense, PReLU, BatchNormalization, Dropout\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","\n","def build_model(cfg):\n","    model = Sequential([\n","        Dense(cfg.hidden_size, input_dim=CFG.num_pred),\n","        BatchNormalization(),\n","        Dropout(cfg.dropout),\n","        PReLU(),\n","        Dense(cfg.hidden_size),\n","        BatchNormalization(),\n","        Dropout(cfg.dropout),\n","        PReLU(),\n","        Dense(1)\n","    ])\n","    return model\n","\n","# テストデータの特徴量の取得\n","test_features = test[['pred_1', 'pred_2']].values\n","\n","# 各フォールドでのテストデータの予測を格納するリスト\n","test_preds = []\n","\n","# OOF (Out Of Fold) predictions\n","oof_preds = np.zeros_like(y)\n","\n","for fold, (train_idx, valid_idx) in enumerate(cv):\n","    print(f\"Fold {fold + 1}\")\n","\n","    # データの取得\n","    X_train, y_train = X[train_idx], y[train_idx]\n","    X_valid, y_valid = X[valid_idx], y[valid_idx]\n","\n","    # モデルの作成\n","    model = build_model(CFG)\n","\n","    model.compile(optimizer=Adam(), loss=mape_loss)\n","\n","    # EarlyStoppingコールバックの定義\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n","\n","    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=32, verbose=1, callbacks=[early_stopping])\n","\n","    # OOF predictions\n","    oof_preds[valid_idx] = model.predict(X_valid).reshape(-1)\n","\n","    print(f\"FINISHI: fold{fold} Score: {mean_absolute_percentage_error(y_valid, oof_preds[valid_idx]):.4f}\")\n","\n","    # テストデータの予測\n","    test_pred = model.predict(test_features).reshape(-1)\n","    test_preds.append(test_pred)\n","\n","# Calculate overall OOF score\n","oof_score = mean_absolute_percentage_error(y, oof_preds)\n","print(\"=\" * 50)\n","print(f\"FINISHI: Whole OOF Score: {oof_score:.4f}\")\n","'''"],"metadata":{"id":"9txZTch6R9J2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FINISHI: Whole OOF Score: 0.4452"],"metadata":{"id":"hO4YAbAFR9Hb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t0a6r8D0cAfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#これは共通"],"metadata":{"id":"6SVcevsfb-NZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# すべてのフォールドの予測の平均を取る\n","test[\"pred\"] = np.mean(test_preds, axis=0)\n","\n","test[[\"id\", \"pred\"]].to_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/exp45_submission_stacking.csv', index=False, header=None)"],"metadata":{"id":"KVThaJyF7hsX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KWXDkVCeI1qp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}