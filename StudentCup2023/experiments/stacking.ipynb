{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcCertK8sk87","executionInfo":{"status":"ok","timestamp":1692271761565,"user_tz":-540,"elapsed":15323,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"f8589b65-a15e-482c-b668-3a597808da23"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60y4waf9ss6H","executionInfo":{"status":"ok","timestamp":1692271769315,"user_tz":-540,"elapsed":7752,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"285f0785-f65e-4217-baf0-d95e2c640970"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.11.3-py3-none-any.whl (225 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cmaes>=0.10.0 (from optuna)\n","  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.19)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n","Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n","Successfully installed Mako-1.2.4 alembic-1.11.3 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"2uarR-RYsgEW","executionInfo":{"status":"ok","timestamp":1692274834390,"user_tz":-540,"elapsed":13815,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"outputs":[],"source":["# ===================================================================\n","#  Library\n","# ===================================================================\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import math\n","import time\n","\n","\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.metrics import mean_absolute_percentage_error\n","from tqdm.auto import tqdm\n","\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","import unicodedata\n","import lightgbm as lgb\n","\n","import optuna\n","import tensorflow as tf\n","from sklearn.metrics import mean_absolute_percentage_error\n","from tensorflow.keras.layers import Dense, PReLU\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qHC5RQzMsgEZ","executionInfo":{"status":"ok","timestamp":1692274834391,"user_tz":-540,"elapsed":16,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"outputs":[],"source":["# ===================================================================\n","#  CFG\n","# ===================================================================\n","class CFG:\n","    seed = 42\n","    n_trials = 3000\n","    num_pred = 2 #予測の数を指定、今回はexp38と39の2つ\n","    hidden_size = 4\n","    dropout = 0.2"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xAwmb2_IsgEa","executionInfo":{"status":"ok","timestamp":1692274834392,"user_tz":-540,"elapsed":16,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"outputs":[],"source":["# ===================================================================\n","#  Utils\n","# ===================================================================\n","def get_score(y_true, y_pred):\n","    \"\"\"get MAPE score\"\"\"\n","    score = mean_absolute_percentage_error(y_true, y_pred)\n","    return score * 100"]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/train.csv')"],"metadata":{"id":"PGfT8Rl7tO1F","executionInfo":{"status":"ok","timestamp":1692274834392,"user_tz":-540,"elapsed":16,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# ===================================================================\n","#  DataLoading\n","# ===================================================================\n","df_1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/exp00038/signate-models/exp38_oof_pred.csv').rename(columns={\"oof_pred\":\"pred_1\"})\n","df_2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/exp00039/signate-models/exp39_oof_pred.csv').rename(columns={\"oof_pred\":\"pred_2\"})\n","df = pd.concat([df_train['id'], df_1, df_2, df_train['price']], axis=1)\n","test_1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/exp00038/signate-models/submission.csv', header=None).rename(columns={0:\"id\", 1:\"pred_1\"})\n","test_2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/exp00039/signate-models/submission.csv', header=None).rename(columns={0:\"id\", 1:\"pred_2\"})\n","test = test_1.merge(test_2, on='id')"],"metadata":{"id":"S-MdT8MUtlRV","executionInfo":{"status":"ok","timestamp":1692274834881,"user_tz":-540,"elapsed":505,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def mape_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    diff = tf.abs((y_true - y_pred) / tf.clip_by_value(tf.abs(y_true), 1e-9, float(\"inf\")))\n","    return 100. * tf.reduce_mean(diff)"],"metadata":{"id":"XXhR478jAUo8","executionInfo":{"status":"ok","timestamp":1692274834882,"user_tz":-540,"elapsed":8,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","set_seed(42)  # ここでシード値を設定"],"metadata":{"id":"VIS0sOQq-KVC","executionInfo":{"status":"ok","timestamp":1692274834882,"user_tz":-540,"elapsed":8,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 交差検証関数の定義\n","def get_custom_cv(df, n_splits):\n","    df = df.sort_values(by=\"price\", ignore_index=True)\n","    df[\"fold\"] = [i for i in range(n_splits)] * (df.shape[0] // n_splits) \\\n","                + [i for i in range(df.shape[0] % n_splits)]\n","    df = df.sort_values(by=\"id\", ignore_index=True)\n","\n","    for fold in range(n_splits):\n","        train_idx = df[df[\"fold\"] != fold].index\n","        valid_idx = df[df[\"fold\"] == fold].index\n","        yield train_idx, valid_idx\n","\n","# CVの設定\n","n_splits = 8\n","cv = list(get_custom_cv(df, n_splits))"],"metadata":{"id":"iiQWoIsi-oxU","executionInfo":{"status":"ok","timestamp":1692274834882,"user_tz":-540,"elapsed":7,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yD0BLcMrKqAB","executionInfo":{"status":"ok","timestamp":1692274834883,"user_tz":-540,"elapsed":8,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 1. データセットの作成\n","X = df[['pred_1', 'pred_2']].values\n","y = df['price'].values"],"metadata":{"id":"Yd-CiZAMAV2Y","executionInfo":{"status":"ok","timestamp":1692274834883,"user_tz":-540,"elapsed":7,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-PSeFIOBR4Uc","executionInfo":{"status":"ok","timestamp":1692274834884,"user_tz":-540,"elapsed":8,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#一つ目のモデル"],"metadata":{"id":"IDmpPWq1R5Ha","executionInfo":{"status":"ok","timestamp":1692274834884,"user_tz":-540,"elapsed":8,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# テストデータの特徴量の取得\n","test_features = test[['pred_1', 'pred_2']].values\n","\n","# 各フォールドでのテストデータの予測を格納するリスト\n","test_preds = []\n","\n","# OOF (Out Of Fold) predictions\n","oof_preds = np.zeros_like(y)\n","\n","for fold, (train_idx, valid_idx) in enumerate(cv):\n","    print(f\"Fold {fold + 1}\")\n","\n","    # データの取得\n","    X_train, y_train = X[train_idx], y[train_idx]\n","    X_valid, y_valid = X[valid_idx], y[valid_idx]\n","\n","    # モデルの作成と学習\n","    model = Sequential([\n","        Dense(CFG.hidden_size*3, input_dim=CFG.num_pred),\n","        PReLU(),\n","        Dense(CFG.hidden_size*2),\n","        PReLU(),\n","        Dense(CFG.hidden_size),\n","        PReLU(),\n","        Dense(1)\n","    ])\n","\n","    model.compile(optimizer=Adam(), loss=mape_loss)\n","\n","    # EarlyStoppingコールバックの定義\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n","\n","    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=32, verbose=1, callbacks=[early_stopping])\n","\n","    # OOF predictions\n","    oof_preds[valid_idx] = model.predict(X_valid).reshape(-1)\n","\n","    print(f\"FINISHI: fold{fold} Score: {mean_absolute_percentage_error(y_valid, oof_preds[valid_idx]):.4f}\")\n","\n","    # テストデータの予測\n","    test_pred = model.predict(test_features).reshape(-1)\n","    test_preds.append(test_pred)\n","\n","# Calculate overall OOF score\n","oof_score = mean_absolute_percentage_error(y, oof_preds)\n","print(\"=\" * 50)\n","print(f\"FINISHI: Whole OOF Score: {oof_score:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8EjG5jb7hul","executionInfo":{"status":"ok","timestamp":1692275935408,"user_tz":-540,"elapsed":1100532,"user":{"displayName":"あらら","userId":"17170718375583812862"}},"outputId":"9b7d68a0-6a7c-4731-c023-c7ceaf6ef461"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n","Epoch 1/50\n","753/753 [==============================] - 9s 7ms/step - loss: 46.8950 - val_loss: 43.6229\n","Epoch 2/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1606 - val_loss: 43.6522\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1705 - val_loss: 43.6942\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1513 - val_loss: 43.6078\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.2069 - val_loss: 43.6419\n","Epoch 6/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1450 - val_loss: 43.6032\n","Epoch 7/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1515 - val_loss: 43.6147\n","Epoch 8/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1687 - val_loss: 43.6170\n","Epoch 9/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1499 - val_loss: 43.6093\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1418 - val_loss: 43.5927\n","Epoch 11/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1390 - val_loss: 43.5926\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1579 - val_loss: 43.7103\n","Epoch 13/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1670 - val_loss: 43.6453\n","Epoch 14/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1180 - val_loss: 43.5989\n","Epoch 15/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1458 - val_loss: 43.6770\n","Epoch 16/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1462 - val_loss: 43.6229\n","Epoch 17/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1453 - val_loss: 43.5937\n","Epoch 18/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0998 - val_loss: 43.5988\n","Epoch 19/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1357 - val_loss: 43.6366\n","Epoch 20/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1375 - val_loss: 43.5797\n","Epoch 21/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1270 - val_loss: 43.7829\n","Epoch 22/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1316 - val_loss: 43.6334\n","Epoch 23/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1433 - val_loss: 43.5869\n","Epoch 24/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1578 - val_loss: 43.5885\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1316 - val_loss: 43.8935\n","Epoch 26/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1297 - val_loss: 43.5799\n","Epoch 27/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1326 - val_loss: 43.5747\n","Epoch 28/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1170 - val_loss: 43.6614\n","Epoch 29/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1211 - val_loss: 43.6335\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1126 - val_loss: 43.5839\n","Epoch 31/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1273 - val_loss: 43.6246\n","Epoch 32/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1434 - val_loss: 43.5715\n","Epoch 33/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1201 - val_loss: 43.5702\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1336 - val_loss: 43.6538\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1515 - val_loss: 43.9437\n","Epoch 36/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1264 - val_loss: 43.5795\n","Epoch 37/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1073 - val_loss: 43.6373\n","Epoch 38/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1318 - val_loss: 43.9749\n","Epoch 39/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1316 - val_loss: 43.6197\n","Epoch 40/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1167 - val_loss: 43.6045\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1314 - val_loss: 43.6507\n","Epoch 42/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1381 - val_loss: 43.5750\n","Epoch 43/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1143 - val_loss: 43.5701\n","Epoch 44/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1173 - val_loss: 43.5709\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1491 - val_loss: 43.7438\n","Epoch 46/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1285 - val_loss: 43.5832\n","Epoch 47/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1129 - val_loss: 43.5898\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1411 - val_loss: 43.6422\n","Epoch 49/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1225 - val_loss: 43.6372\n","Epoch 50/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1064 - val_loss: 43.6554\n","108/108 [==============================] - 0s 1ms/step\n","FINISHI: fold0 Score: 0.4366\n","861/861 [==============================] - 1s 1ms/step\n","Fold 2\n","Epoch 1/50\n","753/753 [==============================] - 5s 4ms/step - loss: 44.2583 - val_loss: 44.5992\n","Epoch 2/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9921 - val_loss: 44.5805\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0184 - val_loss: 44.5248\n","Epoch 4/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0237 - val_loss: 44.5716\n","Epoch 5/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9907 - val_loss: 44.5302\n","Epoch 6/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0110 - val_loss: 44.5055\n","Epoch 7/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9992 - val_loss: 44.5228\n","Epoch 8/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9963 - val_loss: 44.5041\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0243 - val_loss: 44.7518\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0344 - val_loss: 44.5078\n","Epoch 11/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9898 - val_loss: 44.6275\n","Epoch 12/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0184 - val_loss: 44.5547\n","Epoch 13/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0090 - val_loss: 44.9073\n","Epoch 14/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0343 - val_loss: 44.5275\n","Epoch 15/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9818 - val_loss: 44.5067\n","Epoch 16/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0209 - val_loss: 44.5762\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9894 - val_loss: 44.5082\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9961 - val_loss: 44.5196\n","Epoch 19/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0083 - val_loss: 44.5081\n","Epoch 20/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0273 - val_loss: 44.5637\n","Epoch 21/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9952 - val_loss: 44.6494\n","Epoch 22/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0124 - val_loss: 44.5299\n","Epoch 23/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9938 - val_loss: 44.6169\n","Epoch 24/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0000 - val_loss: 44.5177\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0173 - val_loss: 44.5079\n","Epoch 26/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9923 - val_loss: 44.5228\n","Epoch 27/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9903 - val_loss: 44.5067\n","Epoch 28/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9944 - val_loss: 44.5038\n","Epoch 29/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0034 - val_loss: 44.5073\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9952 - val_loss: 44.5392\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0088 - val_loss: 44.6167\n","Epoch 32/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0074 - val_loss: 44.5644\n","Epoch 33/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9957 - val_loss: 44.5060\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9635 - val_loss: 44.6876\n","Epoch 35/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9850 - val_loss: 44.5317\n","Epoch 36/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0107 - val_loss: 44.5321\n","Epoch 37/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9871 - val_loss: 44.6561\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9858 - val_loss: 44.5122\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9848 - val_loss: 44.5733\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9894 - val_loss: 44.5100\n","Epoch 41/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0052 - val_loss: 44.5886\n","Epoch 42/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9891 - val_loss: 44.5077\n","Epoch 43/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0038 - val_loss: 44.6746\n","Epoch 44/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9982 - val_loss: 44.5170\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9750 - val_loss: 44.5296\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9691 - val_loss: 44.5342\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9918 - val_loss: 44.6692\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9851 - val_loss: 44.5235\n","Epoch 49/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0313 - val_loss: 44.5321\n","Epoch 50/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9869 - val_loss: 44.5296\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold1 Score: 0.4453\n","861/861 [==============================] - 2s 2ms/step\n","Fold 3\n","Epoch 1/50\n","753/753 [==============================] - 3s 3ms/step - loss: 60.1606 - val_loss: 43.7790\n","Epoch 2/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1504 - val_loss: 43.6303\n","Epoch 3/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1459 - val_loss: 43.6578\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1701 - val_loss: 43.6085\n","Epoch 5/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1484 - val_loss: 43.6121\n","Epoch 6/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1639 - val_loss: 43.6054\n","Epoch 7/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1468 - val_loss: 43.6300\n","Epoch 8/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1722 - val_loss: 43.6065\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1253 - val_loss: 43.7804\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1128 - val_loss: 43.7166\n","Epoch 11/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1409 - val_loss: 43.8163\n","Epoch 12/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1597 - val_loss: 43.6369\n","Epoch 13/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1469 - val_loss: 43.8182\n","Epoch 14/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1651 - val_loss: 43.8355\n","Epoch 15/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1054 - val_loss: 43.6840\n","Epoch 16/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1438 - val_loss: 43.6455\n","Epoch 17/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1570 - val_loss: 43.6268\n","Epoch 18/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1511 - val_loss: 43.6125\n","Epoch 19/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1332 - val_loss: 43.6140\n","Epoch 20/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1368 - val_loss: 43.7691\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1334 - val_loss: 44.0098\n","Epoch 22/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1273 - val_loss: 43.6962\n","Epoch 23/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1496 - val_loss: 43.6127\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1191 - val_loss: 43.6196\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1793 - val_loss: 43.6627\n","Epoch 26/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0993 - val_loss: 43.7799\n","Epoch 27/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1364 - val_loss: 43.6817\n","Epoch 28/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1618 - val_loss: 43.7510\n","Epoch 29/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1546 - val_loss: 43.8131\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1341 - val_loss: 43.8197\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1264 - val_loss: 43.6870\n","Epoch 32/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1288 - val_loss: 43.7169\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1257 - val_loss: 43.9351\n","Epoch 34/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1537 - val_loss: 43.6532\n","Epoch 35/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1556 - val_loss: 43.6846\n","Epoch 36/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1468 - val_loss: 43.6647\n","Epoch 37/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1566 - val_loss: 43.7491\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1572 - val_loss: 43.6790\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1105 - val_loss: 43.6160\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1366 - val_loss: 43.6281\n","Epoch 41/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1289 - val_loss: 43.6135\n","Epoch 42/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1318 - val_loss: 43.6115\n","Epoch 43/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1342 - val_loss: 43.6113\n","Epoch 44/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1478 - val_loss: 43.6659\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1411 - val_loss: 43.7882\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1468 - val_loss: 43.6117\n","Epoch 47/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1249 - val_loss: 43.6119\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1256 - val_loss: 43.6170\n","Epoch 49/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1400 - val_loss: 43.7641\n","Epoch 50/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1272 - val_loss: 43.6193\n","108/108 [==============================] - 0s 1ms/step\n","FINISHI: fold2 Score: 0.4362\n","861/861 [==============================] - 1s 1ms/step\n","Fold 4\n","Epoch 1/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0630 - val_loss: 45.0546\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9702 - val_loss: 44.9788\n","Epoch 3/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9457 - val_loss: 44.9692\n","Epoch 4/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9740 - val_loss: 45.0342\n","Epoch 5/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9489 - val_loss: 44.9519\n","Epoch 6/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9508 - val_loss: 45.1850\n","Epoch 7/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9459 - val_loss: 44.9584\n","Epoch 8/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9390 - val_loss: 45.1023\n","Epoch 9/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9452 - val_loss: 44.9602\n","Epoch 10/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9614 - val_loss: 45.0704\n","Epoch 11/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9585 - val_loss: 44.9700\n","Epoch 12/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9678 - val_loss: 45.0936\n","Epoch 13/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9129 - val_loss: 44.9811\n","Epoch 14/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9490 - val_loss: 44.9465\n","Epoch 15/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9477 - val_loss: 45.0068\n","Epoch 16/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9493 - val_loss: 44.9654\n","Epoch 17/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9099 - val_loss: 44.9433\n","Epoch 18/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9382 - val_loss: 44.9696\n","Epoch 19/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9606 - val_loss: 44.9817\n","Epoch 20/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9351 - val_loss: 44.9479\n","Epoch 21/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9381 - val_loss: 45.1852\n","Epoch 22/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9440 - val_loss: 44.9484\n","Epoch 23/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9319 - val_loss: 44.9402\n","Epoch 24/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9500 - val_loss: 44.9521\n","Epoch 25/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9303 - val_loss: 45.1102\n","Epoch 26/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9256 - val_loss: 44.9802\n","Epoch 27/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9196 - val_loss: 45.1509\n","Epoch 28/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9396 - val_loss: 44.9522\n","Epoch 29/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9427 - val_loss: 44.9398\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9351 - val_loss: 44.9984\n","Epoch 31/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9354 - val_loss: 44.9433\n","Epoch 32/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9259 - val_loss: 45.0409\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9366 - val_loss: 44.9519\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9128 - val_loss: 45.0269\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9265 - val_loss: 44.9459\n","Epoch 36/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9430 - val_loss: 45.0372\n","Epoch 37/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9401 - val_loss: 44.9492\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9478 - val_loss: 44.9517\n","Epoch 39/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9497 - val_loss: 44.9982\n","Epoch 40/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9503 - val_loss: 44.9408\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9419 - val_loss: 45.0048\n","Epoch 42/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9473 - val_loss: 45.1772\n","Epoch 43/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9194 - val_loss: 44.9402\n","Epoch 44/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9259 - val_loss: 44.9396\n","Epoch 45/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9084 - val_loss: 44.9412\n","Epoch 46/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9031 - val_loss: 45.0051\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9274 - val_loss: 44.9405\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9388 - val_loss: 45.1146\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9130 - val_loss: 45.0623\n","Epoch 50/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9176 - val_loss: 44.9608\n","108/108 [==============================] - 0s 1ms/step\n","FINISHI: fold3 Score: 0.4496\n","861/861 [==============================] - 1s 1ms/step\n","Fold 5\n","Epoch 1/50\n","753/753 [==============================] - 3s 3ms/step - loss: 51.2238 - val_loss: 43.4665\n","Epoch 2/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1810 - val_loss: 43.5542\n","Epoch 3/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1951 - val_loss: 43.4970\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1883 - val_loss: 43.3965\n","Epoch 5/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1704 - val_loss: 43.3656\n","Epoch 6/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1933 - val_loss: 43.6344\n","Epoch 7/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1576 - val_loss: 43.3822\n","Epoch 8/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1841 - val_loss: 43.4033\n","Epoch 9/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1672 - val_loss: 43.3894\n","Epoch 10/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1792 - val_loss: 43.3891\n","Epoch 11/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1849 - val_loss: 43.3659\n","Epoch 12/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1939 - val_loss: 43.3768\n","Epoch 13/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1741 - val_loss: 43.6081\n","Epoch 14/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1689 - val_loss: 43.5140\n","Epoch 15/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1686 - val_loss: 43.6035\n","Epoch 16/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1659 - val_loss: 43.4122\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1536 - val_loss: 43.4405\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1668 - val_loss: 43.4128\n","Epoch 19/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1640 - val_loss: 43.4594\n","Epoch 20/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1614 - val_loss: 43.3714\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1612 - val_loss: 43.4005\n","Epoch 22/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1591 - val_loss: 43.3726\n","Epoch 23/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1660 - val_loss: 43.3751\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1792 - val_loss: 43.3662\n","Epoch 25/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1502 - val_loss: 43.4563\n","Epoch 26/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1553 - val_loss: 43.3977\n","Epoch 27/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1599 - val_loss: 43.4080\n","Epoch 28/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1528 - val_loss: 43.4329\n","Epoch 29/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1636 - val_loss: 43.3658\n","Epoch 30/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1451 - val_loss: 43.3979\n","Epoch 31/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1727 - val_loss: 43.3741\n","Epoch 32/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1803 - val_loss: 43.4693\n","Epoch 33/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1659 - val_loss: 43.5144\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1557 - val_loss: 43.3677\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1450 - val_loss: 43.4971\n","Epoch 36/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1631 - val_loss: 43.3647\n","Epoch 37/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1702 - val_loss: 43.6270\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1537 - val_loss: 43.3634\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1388 - val_loss: 43.4094\n","Epoch 40/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1590 - val_loss: 43.5156\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1550 - val_loss: 43.4067\n","Epoch 42/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1523 - val_loss: 43.5438\n","Epoch 43/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.1529 - val_loss: 43.3713\n","Epoch 44/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1517 - val_loss: 43.3672\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1761 - val_loss: 43.3574\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1533 - val_loss: 43.3577\n","Epoch 47/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1649 - val_loss: 43.4350\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1678 - val_loss: 43.4303\n","Epoch 49/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1489 - val_loss: 43.5093\n","Epoch 50/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1506 - val_loss: 43.3994\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold4 Score: 0.4340\n","861/861 [==============================] - 2s 2ms/step\n","Fold 6\n","Epoch 1/50\n","753/753 [==============================] - 4s 3ms/step - loss: 46.2463 - val_loss: 43.2019\n","Epoch 2/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.2847 - val_loss: 43.2508\n","Epoch 3/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.2281 - val_loss: 43.2106\n","Epoch 4/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.2308 - val_loss: 43.2921\n","Epoch 5/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.2237 - val_loss: 43.2499\n","Epoch 6/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.2052 - val_loss: 43.3465\n","Epoch 7/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.2170 - val_loss: 43.2189\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1965 - val_loss: 43.2485\n","Epoch 9/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.2124 - val_loss: 43.2227\n","Epoch 10/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.2036 - val_loss: 43.2231\n","Epoch 11/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1964 - val_loss: 43.2269\n","Epoch 12/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1982 - val_loss: 43.3944\n","Epoch 13/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.2021 - val_loss: 43.2402\n","Epoch 14/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1906 - val_loss: 43.3405\n","Epoch 15/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1790 - val_loss: 43.6560\n","Epoch 16/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.2041 - val_loss: 43.3029\n","Epoch 17/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1649 - val_loss: 43.2971\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1876 - val_loss: 43.3565\n","Epoch 19/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1723 - val_loss: 43.4518\n","Epoch 20/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1670 - val_loss: 43.3183\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1812 - val_loss: 43.4096\n","Epoch 22/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1575 - val_loss: 43.2931\n","Epoch 23/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1773 - val_loss: 43.2676\n","Epoch 24/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1496 - val_loss: 43.2724\n","Epoch 25/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1864 - val_loss: 43.2663\n","Epoch 26/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1830 - val_loss: 43.2752\n","Epoch 27/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1649 - val_loss: 43.5131\n","Epoch 28/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1667 - val_loss: 43.2843\n","Epoch 29/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1848 - val_loss: 43.3732\n","Epoch 30/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1598 - val_loss: 43.2801\n","Epoch 31/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.2013 - val_loss: 43.2906\n","Epoch 32/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1714 - val_loss: 43.2847\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1578 - val_loss: 43.6352\n","Epoch 34/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1511 - val_loss: 43.3454\n","Epoch 35/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1519 - val_loss: 43.5293\n","Epoch 36/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1592 - val_loss: 43.3844\n","Epoch 37/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1636 - val_loss: 43.2954\n","Epoch 38/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1831 - val_loss: 43.2998\n","Epoch 39/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1748 - val_loss: 43.3718\n","Epoch 40/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1618 - val_loss: 43.3935\n","Epoch 41/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1625 - val_loss: 43.3601\n","Epoch 42/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1805 - val_loss: 43.2952\n","Epoch 43/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1629 - val_loss: 43.3632\n","Epoch 44/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1475 - val_loss: 43.2894\n","Epoch 45/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1518 - val_loss: 43.2962\n","Epoch 46/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1616 - val_loss: 43.3503\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1541 - val_loss: 43.3042\n","Epoch 48/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1947 - val_loss: 43.2945\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1562 - val_loss: 43.5010\n","Epoch 50/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1782 - val_loss: 43.2878\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold5 Score: 0.4329\n","861/861 [==============================] - 2s 2ms/step\n","Fold 7\n","Epoch 1/50\n","753/753 [==============================] - 3s 3ms/step - loss: 55.9775 - val_loss: 44.7867\n","Epoch 2/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9990 - val_loss: 44.8836\n","Epoch 3/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9989 - val_loss: 45.0434\n","Epoch 4/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9434 - val_loss: 45.3447\n","Epoch 5/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9747 - val_loss: 45.0308\n","Epoch 6/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9941 - val_loss: 44.8773\n","Epoch 7/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9990 - val_loss: 45.0613\n","Epoch 8/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9699 - val_loss: 44.8363\n","Epoch 9/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9730 - val_loss: 44.7493\n","Epoch 10/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9692 - val_loss: 44.9012\n","Epoch 11/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9571 - val_loss: 44.8275\n","Epoch 12/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9786 - val_loss: 44.9474\n","Epoch 13/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9930 - val_loss: 44.9978\n","Epoch 14/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9677 - val_loss: 44.8988\n","Epoch 15/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9717 - val_loss: 45.0849\n","Epoch 16/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9691 - val_loss: 44.7906\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9755 - val_loss: 44.7993\n","Epoch 18/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9585 - val_loss: 44.7553\n","Epoch 19/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9977 - val_loss: 45.2376\n","Epoch 20/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9497 - val_loss: 44.7556\n","Epoch 21/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9760 - val_loss: 44.9190\n","Epoch 22/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9713 - val_loss: 45.3512\n","Epoch 23/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9537 - val_loss: 44.9129\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9881 - val_loss: 44.9010\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9768 - val_loss: 44.8961\n","Epoch 26/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9719 - val_loss: 44.7590\n","Epoch 27/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9665 - val_loss: 44.8344\n","Epoch 28/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9431 - val_loss: 45.0142\n","Epoch 29/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9825 - val_loss: 44.9551\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9492 - val_loss: 44.9015\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9515 - val_loss: 44.8318\n","Epoch 32/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9745 - val_loss: 44.8617\n","Epoch 33/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9636 - val_loss: 44.8345\n","Epoch 34/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9649 - val_loss: 44.7625\n","Epoch 35/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9684 - val_loss: 44.7966\n","Epoch 36/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9802 - val_loss: 44.7926\n","Epoch 37/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9773 - val_loss: 44.7908\n","Epoch 38/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9706 - val_loss: 45.0950\n","Epoch 39/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9508 - val_loss: 45.4336\n","Epoch 40/50\n","753/753 [==============================] - 3s 3ms/step - loss: 43.9738 - val_loss: 44.7923\n","Epoch 41/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9679 - val_loss: 44.8008\n","Epoch 42/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9702 - val_loss: 44.7931\n","Epoch 43/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9553 - val_loss: 44.8859\n","Epoch 44/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9565 - val_loss: 44.8280\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9767 - val_loss: 44.8313\n","Epoch 46/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9608 - val_loss: 45.0207\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9609 - val_loss: 44.8402\n","Epoch 48/50\n","753/753 [==============================] - 3s 4ms/step - loss: 43.9712 - val_loss: 44.8952\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 43.9659 - val_loss: 45.5369\n","Epoch 50/50\n","753/753 [==============================] - 2s 2ms/step - loss: 43.9436 - val_loss: 44.7621\n","108/108 [==============================] - 0s 2ms/step\n","FINISHI: fold6 Score: 0.4476\n","861/861 [==============================] - 1s 1ms/step\n","Fold 8\n","Epoch 1/50\n","753/753 [==============================] - 3s 3ms/step - loss: 52.1684 - val_loss: 44.0772\n","Epoch 2/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1385 - val_loss: 44.0852\n","Epoch 3/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1354 - val_loss: 44.0862\n","Epoch 4/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1235 - val_loss: 44.0358\n","Epoch 5/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1286 - val_loss: 44.1353\n","Epoch 6/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0849 - val_loss: 44.1577\n","Epoch 7/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1122 - val_loss: 44.0059\n","Epoch 8/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0974 - val_loss: 44.0303\n","Epoch 9/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0869 - val_loss: 44.0067\n","Epoch 10/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0711 - val_loss: 44.1119\n","Epoch 11/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1295 - val_loss: 44.0079\n","Epoch 12/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1068 - val_loss: 44.1392\n","Epoch 13/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0887 - val_loss: 44.0249\n","Epoch 14/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0900 - val_loss: 44.1752\n","Epoch 15/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0799 - val_loss: 44.1770\n","Epoch 16/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0616 - val_loss: 44.0017\n","Epoch 17/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0938 - val_loss: 44.1993\n","Epoch 18/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0840 - val_loss: 43.9748\n","Epoch 19/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1097 - val_loss: 43.9977\n","Epoch 20/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0928 - val_loss: 44.0444\n","Epoch 21/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1028 - val_loss: 44.3449\n","Epoch 22/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0750 - val_loss: 44.0261\n","Epoch 23/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0927 - val_loss: 43.9875\n","Epoch 24/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0897 - val_loss: 43.9864\n","Epoch 25/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0945 - val_loss: 43.9803\n","Epoch 26/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1183 - val_loss: 43.9682\n","Epoch 27/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.1163 - val_loss: 44.2758\n","Epoch 28/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1046 - val_loss: 43.9820\n","Epoch 29/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.1081 - val_loss: 43.9770\n","Epoch 30/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.1111 - val_loss: 44.1098\n","Epoch 31/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0660 - val_loss: 44.5451\n","Epoch 32/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0854 - val_loss: 44.0205\n","Epoch 33/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0836 - val_loss: 44.0897\n","Epoch 34/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0877 - val_loss: 43.9871\n","Epoch 35/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0744 - val_loss: 43.9817\n","Epoch 36/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0846 - val_loss: 43.9967\n","Epoch 37/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0866 - val_loss: 43.9738\n","Epoch 38/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0913 - val_loss: 44.0988\n","Epoch 39/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0803 - val_loss: 44.0858\n","Epoch 40/50\n","753/753 [==============================] - 3s 3ms/step - loss: 44.0818 - val_loss: 43.9736\n","Epoch 41/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0632 - val_loss: 44.0316\n","Epoch 42/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0822 - val_loss: 44.3355\n","Epoch 43/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0666 - val_loss: 44.3658\n","Epoch 44/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0814 - val_loss: 44.1950\n","Epoch 45/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0685 - val_loss: 43.9824\n","Epoch 46/50\n","753/753 [==============================] - 2s 2ms/step - loss: 44.0728 - val_loss: 43.9661\n","Epoch 47/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0649 - val_loss: 43.9704\n","Epoch 48/50\n","753/753 [==============================] - 3s 4ms/step - loss: 44.0964 - val_loss: 44.1709\n","Epoch 49/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0830 - val_loss: 44.0394\n","Epoch 50/50\n","753/753 [==============================] - 2s 3ms/step - loss: 44.0583 - val_loss: 44.0916\n","108/108 [==============================] - 0s 1ms/step\n","FINISHI: fold7 Score: 0.4409\n","861/861 [==============================] - 2s 2ms/step\n","==================================================\n","FINISHI: Whole OOF Score: 0.4404\n"]}]},{"cell_type":"code","source":["hidden_size = 8\n","FINISHI: Whole OOF Score: 0.4404\n","\n","hidden_size = 4\n","FINISHI: Whole OOF Score: 0.4404"],"metadata":{"id":"hzrsnzBdIwe3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#二つ目のモデル、こっちはあんまり期待できなさそうかも？"],"metadata":{"id":"fHGMPXqWSlBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","from keras.models import Sequential\n","from keras.layers import Dense, PReLU, BatchNormalization, Dropout\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping\n","\n","def build_model(cfg):\n","    model = Sequential([\n","        Dense(cfg.hidden_size, input_dim=CFG.num_pred),\n","        BatchNormalization(),\n","        Dropout(cfg.dropout),\n","        PReLU(),\n","        Dense(cfg.hidden_size),\n","        BatchNormalization(),\n","        Dropout(cfg.dropout),\n","        PReLU(),\n","        Dense(1)\n","    ])\n","    return model\n","\n","# テストデータの特徴量の取得\n","test_features = test[['pred_1', 'pred_2']].values\n","\n","# 各フォールドでのテストデータの予測を格納するリスト\n","test_preds = []\n","\n","# OOF (Out Of Fold) predictions\n","oof_preds = np.zeros_like(y)\n","\n","for fold, (train_idx, valid_idx) in enumerate(cv):\n","    print(f\"Fold {fold + 1}\")\n","\n","    # データの取得\n","    X_train, y_train = X[train_idx], y[train_idx]\n","    X_valid, y_valid = X[valid_idx], y[valid_idx]\n","\n","    # モデルの作成\n","    model = build_model(CFG)\n","\n","    model.compile(optimizer=Adam(), loss=mape_loss)\n","\n","    # EarlyStoppingコールバックの定義\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, restore_best_weights=True)\n","\n","    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=32, verbose=1, callbacks=[early_stopping])\n","\n","    # OOF predictions\n","    oof_preds[valid_idx] = model.predict(X_valid).reshape(-1)\n","\n","    print(f\"FINISHI: fold{fold} Score: {mean_absolute_percentage_error(y_valid, oof_preds[valid_idx]):.4f}\")\n","\n","    # テストデータの予測\n","    test_pred = model.predict(test_features).reshape(-1)\n","    test_preds.append(test_pred)\n","\n","# Calculate overall OOF score\n","oof_score = mean_absolute_percentage_error(y, oof_preds)\n","print(\"=\" * 50)\n","print(f\"FINISHI: Whole OOF Score: {oof_score:.4f}\")\n","'''"],"metadata":{"id":"9txZTch6R9J2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FINISHI: Whole OOF Score: 0.4452"],"metadata":{"id":"hO4YAbAFR9Hb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t0a6r8D0cAfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#これは共通"],"metadata":{"id":"6SVcevsfb-NZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# すべてのフォールドの予測の平均を取る\n","test[\"pred\"] = np.mean(test_preds, axis=0)\n","\n","test[[\"id\", \"pred\"]].to_csv('/content/drive/MyDrive/Colab Notebooks/signate2023/exp38_39_submission_stacking_cv.csv', index=False, header=None)"],"metadata":{"id":"KVThaJyF7hsX","executionInfo":{"status":"ok","timestamp":1692269759087,"user_tz":-540,"elapsed":255,"user":{"displayName":"あらら","userId":"17170718375583812862"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KWXDkVCeI1qp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}